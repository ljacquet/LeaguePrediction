{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, pickle, datetime, numpy as np, math\n",
    "\n",
    "# ML\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from keras import backend as K\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import sys\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data: 06:31PM on July 10, 2019\n",
      "./Data\\GameData.2019.07.10.pickle\n",
      "./Data\\PlayerData.2019.07.10.pickle\n",
      "./Data\\ChampData.2019.07.10.pickle\n"
     ]
    }
   ],
   "source": [
    "# Get List of Current Data Files\n",
    "game = glob.glob(\"./Data/GameData*.pickle\")\n",
    "player = glob.glob(\"./Data/PlayerData*.pickle\")\n",
    "champ = glob.glob(\"./Data/ChampData*.pickle\")\n",
    "\n",
    "# Sort to find the most recent\n",
    "game.sort()\n",
    "player.sort()\n",
    "champ.sort()\n",
    "\n",
    "# Open Most Recent File\n",
    "with open(game[-1], 'rb') as handle:\n",
    "    gameData = pickle.load(handle)\n",
    "    \n",
    "with open(player[-1], 'rb') as handle:\n",
    "    userData = pickle.load(handle)\n",
    "    \n",
    "with open(champ[-1], 'rb') as handle:\n",
    "    champData = pickle.load(handle)\n",
    "\n",
    "print(\"Loaded Data: \" + datetime.datetime.now().strftime(\"%I:%M%p on %B %d, %Y\") + \"\\n{}\\n{}\\n{}\".format(game[-1], player[-1], champ[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function for removing Outliers\n",
    "def removeOutliers(x, outlierConstant = 1.5):\n",
    "    a = np.array(x)\n",
    "    upper_quartile = np.percentile(a, 75)\n",
    "    lower_quartile = np.percentile(a, 25)\n",
    "    IQR = (upper_quartile - lower_quartile) * outlierConstant\n",
    "    quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "    resultList = []\n",
    "    for y in a.tolist():\n",
    "        if y >= quartileSet[0] and y <= quartileSet[1]:\n",
    "            resultList.append(y)\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "AllDataArray_X = []\n",
    "AllDataArray_Y = []\n",
    "\n",
    "# Find Mean and STD DEV of Mastery\n",
    "count = 0\n",
    "\n",
    "for player in userData:\n",
    "    for champ in userData[player]['champions']:\n",
    "        count += 1\n",
    "\n",
    "# Find and graph z-scores of mastery\n",
    "AllMastery = np.empty(count)\n",
    "count = 0\n",
    "\n",
    "for player in userData:\n",
    "    for champ in userData[player]['champions']:\n",
    "        AllMastery[count] = userData[player]['champions'][champ]['points']\n",
    "        count += 1\n",
    "        \n",
    "MasteryMod = removeOutliers(AllMastery)\n",
    "MasteryDev = np.std(MasteryMod)\n",
    "MasteryMean = np.mean(MasteryMod)\n",
    "\n",
    "# Create Array\n",
    "for game in gameData:\n",
    "    #Find Total Level and Rank\n",
    "    totalLevel = 0\n",
    "    totalRank = 1\n",
    "    for user in game['players']:\n",
    "        totalLevel += int(userData[user['accountID']]['level'])\n",
    "        totalRank += int(userData[user['accountID']]['rank'])\n",
    "    \n",
    "    x = []\n",
    "    for user in game['players']:\n",
    "        #print(user)\n",
    "        #print(user['championID'])\n",
    "        try:\n",
    "            x = x + [champData[user['championID']],\n",
    "                np.cbrt((userData[user['accountID']]['champions'][user['championID']]['points'] - MasteryMean) / MasteryDev),\n",
    "                userData[user['accountID']]['rank'] / totalRank,\n",
    "                userData[user['accountID']]['level'] / totalLevel]\n",
    "        except ValueError:\n",
    "            print((userData[user['accountID']]['champions'][user['championID']]['points'] - MasteryMean) / MasteryDev)\n",
    "        \n",
    "                \n",
    "    AllDataArray_X.append(x)\n",
    "    AllDataArray_Y.append([int(game['winner']), int(not game['winner'])])\n",
    "\n",
    "seperator = math.floor((len(AllDataArray_Y) - 1) / 4)\n",
    "\n",
    "# Create Test and Training Data Sets\n",
    "test_x = np.array(AllDataArray_X[0:seperator])\n",
    "test_y = np.array(AllDataArray_Y[0:seperator])\n",
    "\n",
    "train_x = np.array(AllDataArray_X[seperator:])\n",
    "train_y = np.array(AllDataArray_Y[seperator:])\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(64, input_dim=40))\n",
    "model.add(keras.layers.Activation('tanh'))\n",
    "model.add(keras.layers.Dense(32))\n",
    "model.add(keras.layers.Activation('tanh'))\n",
    "model.add(keras.layers.Dense(2))\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Model Created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76 samples, validate on 24 samples\n",
      "Started\n",
      "Epoch 1/20\n",
      "76/76 [==============================] - 0s 4ms/sample - loss: 0.7776 - acc: 0.5132 - val_loss: 0.7254 - val_acc: 0.4583\n",
      "Epoch 2/20\n",
      "76/76 [==============================] - 0s 197us/sample - loss: 0.7254 - acc: 0.5263 - val_loss: 0.7126 - val_acc: 0.4583\n"
     ]
    }
   ],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.endLosses = [.5]\n",
    "        self.endLossesX = [0]\n",
    "        self.count = 0\n",
    "        print(\"Started\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('acc'))\n",
    "        self.count += 1\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.endLosses.append(logs.get('val_acc'))\n",
    "        self.endLossesX.append(self.count)\n",
    "\n",
    "history = LossHistory()\n",
    "myhistory = model.fit(train_x, train_y, \n",
    "                      epochs=20, verbose=1, \n",
    "                      validation_data=[test_x, test_y],\n",
    "                      callbacks=[history, keras.callbacks.EarlyStopping(monitor='val_acc', mode='max', patience=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "24/24 [==============================] - 0s 83us/sample - loss: 0.7126 - acc: 0.4583\n"
     ]
    }
   ],
   "source": [
    "history = model.evaluate(test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
